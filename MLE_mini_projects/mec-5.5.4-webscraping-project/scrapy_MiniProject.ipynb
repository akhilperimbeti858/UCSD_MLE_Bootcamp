{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "scarapy_MiniProject.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "8J6K8QRpCfHP"
      },
      "source": [
        "!pip install scrapy\n",
        "!pip install feedparser"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2boFJ3uZMYZN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "815f0be9-b02d-4197-e8bb-f73c568b460f"
      },
      "source": [
        "!scrapy runspider toscrape_css.py -a tag=humor"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-03-07 02:19:16 [scrapy.utils.log] INFO: Scrapy 2.4.1 started (bot: scrapybot)\n",
            "2021-03-07 02:19:16 [scrapy.utils.log] INFO: Versions: lxml 4.2.6.0, libxml2 2.9.8, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 21.2.0, Python 3.7.10 (default, Feb 20 2021, 21:17:23) - [GCC 7.5.0], pyOpenSSL 20.0.1 (OpenSSL 1.1.1j  16 Feb 2021), cryptography 3.4.6, Platform Linux-4.19.112+-x86_64-with-Ubuntu-18.04-bionic\n",
            "2021-03-07 02:19:16 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor\n",
            "2021-03-07 02:19:16 [scrapy.crawler] INFO: Overridden settings:\n",
            "{'SPIDER_LOADER_WARN_ONLY': True}\n",
            "2021-03-07 02:19:16 [scrapy.extensions.telnet] INFO: Telnet Password: 3c4f923d9fecb413\n",
            "2021-03-07 02:19:16 [scrapy.middleware] INFO: Enabled extensions:\n",
            "['scrapy.extensions.corestats.CoreStats',\n",
            " 'scrapy.extensions.telnet.TelnetConsole',\n",
            " 'scrapy.extensions.memusage.MemoryUsage',\n",
            " 'scrapy.extensions.logstats.LogStats']\n",
            "2021-03-07 02:19:16 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
            "['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
            " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
            " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
            " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
            " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
            " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
            " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
            " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
            " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
            " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
            " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
            "2021-03-07 02:19:16 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
            "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
            " 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',\n",
            " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
            " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
            " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
            "2021-03-07 02:19:16 [scrapy.middleware] INFO: Enabled item pipelines:\n",
            "[]\n",
            "2021-03-07 02:19:16 [scrapy.core.engine] INFO: Spider opened\n",
            "2021-03-07 02:19:16 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
            "2021-03-07 02:19:16 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023\n",
            "2021-03-07 02:19:16 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (308) to <GET http://quotes.toscrape.com/tag/humor/> from <GET http://quotes.toscrape.com/tag/humor>\n",
            "2021-03-07 02:19:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://quotes.toscrape.com/tag/humor/> (referer: None)\n",
            "2021-03-07 02:19:16 [scrapy.core.scraper] DEBUG: Scraped from <200 http://quotes.toscrape.com/tag/humor/>\n",
            "{'text': '“The person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.”', 'author': 'Jane Austen'}\n",
            "2021-03-07 02:19:16 [scrapy.core.scraper] DEBUG: Scraped from <200 http://quotes.toscrape.com/tag/humor/>\n",
            "{'text': '“A day without sunshine is like, you know, night.”', 'author': 'Steve Martin'}\n",
            "2021-03-07 02:19:16 [scrapy.core.scraper] DEBUG: Scraped from <200 http://quotes.toscrape.com/tag/humor/>\n",
            "{'text': '“Anyone who thinks sitting in church can make you a Christian must also think that sitting in a garage can make you a car.”', 'author': 'Garrison Keillor'}\n",
            "2021-03-07 02:19:16 [scrapy.core.scraper] DEBUG: Scraped from <200 http://quotes.toscrape.com/tag/humor/>\n",
            "{'text': '“Beauty is in the eye of the beholder and it may be necessary from time to time to give a stupid or misinformed beholder a black eye.”', 'author': 'Jim Henson'}\n",
            "2021-03-07 02:19:16 [scrapy.core.scraper] DEBUG: Scraped from <200 http://quotes.toscrape.com/tag/humor/>\n",
            "{'text': \"“All you need is love. But a little chocolate now and then doesn't hurt.”\", 'author': 'Charles M. Schulz'}\n",
            "2021-03-07 02:19:16 [scrapy.core.scraper] DEBUG: Scraped from <200 http://quotes.toscrape.com/tag/humor/>\n",
            "{'text': \"“Remember, we're madly in love, so it's all right to kiss me anytime you feel like it.”\", 'author': 'Suzanne Collins'}\n",
            "2021-03-07 02:19:16 [scrapy.core.scraper] DEBUG: Scraped from <200 http://quotes.toscrape.com/tag/humor/>\n",
            "{'text': '“Some people never go crazy. What truly horrible lives they must lead.”', 'author': 'Charles Bukowski'}\n",
            "2021-03-07 02:19:16 [scrapy.core.scraper] DEBUG: Scraped from <200 http://quotes.toscrape.com/tag/humor/>\n",
            "{'text': '“The trouble with having an open mind, of course, is that people will insist on coming along and trying to put things in it.”', 'author': 'Terry Pratchett'}\n",
            "2021-03-07 02:19:16 [scrapy.core.scraper] DEBUG: Scraped from <200 http://quotes.toscrape.com/tag/humor/>\n",
            "{'text': '“Think left and think right and think low and think high. Oh, the thinks you can think up if only you try!”', 'author': 'Dr. Seuss'}\n",
            "2021-03-07 02:19:16 [scrapy.core.scraper] DEBUG: Scraped from <200 http://quotes.toscrape.com/tag/humor/>\n",
            "{'text': '“The reason I talk to myself is because I’m the only one whose answers I accept.”', 'author': 'George Carlin'}\n",
            "2021-03-07 02:19:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://quotes.toscrape.com/tag/humor/page/2/> (referer: http://quotes.toscrape.com/tag/humor/)\n",
            "2021-03-07 02:19:16 [scrapy.core.scraper] DEBUG: Scraped from <200 http://quotes.toscrape.com/tag/humor/page/2/>\n",
            "{'text': '“I am free of all prejudice. I hate everyone equally. ”', 'author': 'W.C. Fields'}\n",
            "2021-03-07 02:19:16 [scrapy.core.scraper] DEBUG: Scraped from <200 http://quotes.toscrape.com/tag/humor/page/2/>\n",
            "{'text': \"“A lady's imagination is very rapid; it jumps from admiration to love, from love to matrimony in a moment.”\", 'author': 'Jane Austen'}\n",
            "2021-03-07 02:19:16 [scrapy.core.engine] INFO: Closing spider (finished)\n",
            "2021-03-07 02:19:16 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
            "{'downloader/request_bytes': 741,\n",
            " 'downloader/request_count': 3,\n",
            " 'downloader/request_method_count/GET': 3,\n",
            " 'downloader/response_bytes': 3977,\n",
            " 'downloader/response_count': 3,\n",
            " 'downloader/response_status_count/200': 2,\n",
            " 'downloader/response_status_count/308': 1,\n",
            " 'elapsed_time_seconds': 0.423305,\n",
            " 'finish_reason': 'finished',\n",
            " 'finish_time': datetime.datetime(2021, 3, 7, 2, 19, 16, 959496),\n",
            " 'item_scraped_count': 12,\n",
            " 'log_count/DEBUG': 15,\n",
            " 'log_count/INFO': 10,\n",
            " 'memusage/max': 81301504,\n",
            " 'memusage/startup': 81301504,\n",
            " 'request_depth_max': 1,\n",
            " 'response_received_count': 2,\n",
            " 'scheduler/dequeued': 3,\n",
            " 'scheduler/dequeued/memory': 3,\n",
            " 'scheduler/enqueued': 3,\n",
            " 'scheduler/enqueued/memory': 3,\n",
            " 'start_time': datetime.datetime(2021, 3, 7, 2, 19, 16, 536191)}\n",
            "2021-03-07 02:19:16 [scrapy.core.engine] INFO: Spider closed (finished)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_mNJ4mIMYb0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "269a7145-3d75-4c6d-cba7-6b9dd654ba53"
      },
      "source": [
        "!scrapy runspider toscrape_css.py -o css_scraper_results.json -a tag=humor"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-03-07 02:19:56 [scrapy.utils.log] INFO: Scrapy 2.4.1 started (bot: scrapybot)\n",
            "2021-03-07 02:19:56 [scrapy.utils.log] INFO: Versions: lxml 4.2.6.0, libxml2 2.9.8, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 21.2.0, Python 3.7.10 (default, Feb 20 2021, 21:17:23) - [GCC 7.5.0], pyOpenSSL 20.0.1 (OpenSSL 1.1.1j  16 Feb 2021), cryptography 3.4.6, Platform Linux-4.19.112+-x86_64-with-Ubuntu-18.04-bionic\n",
            "2021-03-07 02:19:56 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor\n",
            "2021-03-07 02:19:56 [scrapy.crawler] INFO: Overridden settings:\n",
            "{'SPIDER_LOADER_WARN_ONLY': True}\n",
            "2021-03-07 02:19:56 [scrapy.extensions.telnet] INFO: Telnet Password: c6854f7ae0239ac9\n",
            "2021-03-07 02:19:56 [scrapy.middleware] INFO: Enabled extensions:\n",
            "['scrapy.extensions.corestats.CoreStats',\n",
            " 'scrapy.extensions.telnet.TelnetConsole',\n",
            " 'scrapy.extensions.memusage.MemoryUsage',\n",
            " 'scrapy.extensions.feedexport.FeedExporter',\n",
            " 'scrapy.extensions.logstats.LogStats']\n",
            "2021-03-07 02:19:57 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
            "['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
            " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
            " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
            " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
            " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
            " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
            " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
            " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
            " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
            " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
            " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
            "2021-03-07 02:19:57 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
            "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
            " 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',\n",
            " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
            " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
            " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
            "2021-03-07 02:19:57 [scrapy.middleware] INFO: Enabled item pipelines:\n",
            "[]\n",
            "2021-03-07 02:19:57 [scrapy.core.engine] INFO: Spider opened\n",
            "2021-03-07 02:19:57 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
            "2021-03-07 02:19:57 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023\n",
            "2021-03-07 02:19:57 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (308) to <GET http://quotes.toscrape.com/tag/humor/> from <GET http://quotes.toscrape.com/tag/humor>\n",
            "2021-03-07 02:19:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://quotes.toscrape.com/tag/humor/> (referer: None)\n",
            "2021-03-07 02:19:57 [scrapy.core.scraper] DEBUG: Scraped from <200 http://quotes.toscrape.com/tag/humor/>\n",
            "{'text': '“The person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.”', 'author': 'Jane Austen'}\n",
            "2021-03-07 02:19:57 [scrapy.core.scraper] DEBUG: Scraped from <200 http://quotes.toscrape.com/tag/humor/>\n",
            "{'text': '“A day without sunshine is like, you know, night.”', 'author': 'Steve Martin'}\n",
            "2021-03-07 02:19:57 [scrapy.core.scraper] DEBUG: Scraped from <200 http://quotes.toscrape.com/tag/humor/>\n",
            "{'text': '“Anyone who thinks sitting in church can make you a Christian must also think that sitting in a garage can make you a car.”', 'author': 'Garrison Keillor'}\n",
            "2021-03-07 02:19:57 [scrapy.core.scraper] DEBUG: Scraped from <200 http://quotes.toscrape.com/tag/humor/>\n",
            "{'text': '“Beauty is in the eye of the beholder and it may be necessary from time to time to give a stupid or misinformed beholder a black eye.”', 'author': 'Jim Henson'}\n",
            "2021-03-07 02:19:57 [scrapy.core.scraper] DEBUG: Scraped from <200 http://quotes.toscrape.com/tag/humor/>\n",
            "{'text': \"“All you need is love. But a little chocolate now and then doesn't hurt.”\", 'author': 'Charles M. Schulz'}\n",
            "2021-03-07 02:19:57 [scrapy.core.scraper] DEBUG: Scraped from <200 http://quotes.toscrape.com/tag/humor/>\n",
            "{'text': \"“Remember, we're madly in love, so it's all right to kiss me anytime you feel like it.”\", 'author': 'Suzanne Collins'}\n",
            "2021-03-07 02:19:57 [scrapy.core.scraper] DEBUG: Scraped from <200 http://quotes.toscrape.com/tag/humor/>\n",
            "{'text': '“Some people never go crazy. What truly horrible lives they must lead.”', 'author': 'Charles Bukowski'}\n",
            "2021-03-07 02:19:57 [scrapy.core.scraper] DEBUG: Scraped from <200 http://quotes.toscrape.com/tag/humor/>\n",
            "{'text': '“The trouble with having an open mind, of course, is that people will insist on coming along and trying to put things in it.”', 'author': 'Terry Pratchett'}\n",
            "2021-03-07 02:19:57 [scrapy.core.scraper] DEBUG: Scraped from <200 http://quotes.toscrape.com/tag/humor/>\n",
            "{'text': '“Think left and think right and think low and think high. Oh, the thinks you can think up if only you try!”', 'author': 'Dr. Seuss'}\n",
            "2021-03-07 02:19:57 [scrapy.core.scraper] DEBUG: Scraped from <200 http://quotes.toscrape.com/tag/humor/>\n",
            "{'text': '“The reason I talk to myself is because I’m the only one whose answers I accept.”', 'author': 'George Carlin'}\n",
            "2021-03-07 02:19:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://quotes.toscrape.com/tag/humor/page/2/> (referer: http://quotes.toscrape.com/tag/humor/)\n",
            "2021-03-07 02:19:57 [scrapy.core.scraper] DEBUG: Scraped from <200 http://quotes.toscrape.com/tag/humor/page/2/>\n",
            "{'text': '“I am free of all prejudice. I hate everyone equally. ”', 'author': 'W.C. Fields'}\n",
            "2021-03-07 02:19:57 [scrapy.core.scraper] DEBUG: Scraped from <200 http://quotes.toscrape.com/tag/humor/page/2/>\n",
            "{'text': \"“A lady's imagination is very rapid; it jumps from admiration to love, from love to matrimony in a moment.”\", 'author': 'Jane Austen'}\n",
            "2021-03-07 02:19:57 [scrapy.core.engine] INFO: Closing spider (finished)\n",
            "2021-03-07 02:19:57 [scrapy.extensions.feedexport] INFO: Stored json feed (12 items) in: css_scraper_results.json\n",
            "2021-03-07 02:19:57 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
            "{'downloader/request_bytes': 741,\n",
            " 'downloader/request_count': 3,\n",
            " 'downloader/request_method_count/GET': 3,\n",
            " 'downloader/response_bytes': 3989,\n",
            " 'downloader/response_count': 3,\n",
            " 'downloader/response_status_count/200': 2,\n",
            " 'downloader/response_status_count/308': 1,\n",
            " 'elapsed_time_seconds': 0.443391,\n",
            " 'finish_reason': 'finished',\n",
            " 'finish_time': datetime.datetime(2021, 3, 7, 2, 19, 57, 471141),\n",
            " 'item_scraped_count': 12,\n",
            " 'log_count/DEBUG': 15,\n",
            " 'log_count/INFO': 11,\n",
            " 'memusage/max': 81559552,\n",
            " 'memusage/startup': 81559552,\n",
            " 'request_depth_max': 1,\n",
            " 'response_received_count': 2,\n",
            " 'scheduler/dequeued': 3,\n",
            " 'scheduler/dequeued/memory': 3,\n",
            " 'scheduler/enqueued': 3,\n",
            " 'scheduler/enqueued/memory': 3,\n",
            " 'start_time': datetime.datetime(2021, 3, 7, 2, 19, 57, 27750)}\n",
            "2021-03-07 02:19:57 [scrapy.core.engine] INFO: Spider closed (finished)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G3yEBeBnMYeg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48f68b53-ab23-459e-9bd5-22e3bd8111e2"
      },
      "source": [
        "!scrapy runspider toscrape_xpath.py -a tag=humor"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-03-07 02:20:30 [scrapy.utils.log] INFO: Scrapy 2.4.1 started (bot: scrapybot)\n",
            "2021-03-07 02:20:30 [scrapy.utils.log] INFO: Versions: lxml 4.2.6.0, libxml2 2.9.8, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 21.2.0, Python 3.7.10 (default, Feb 20 2021, 21:17:23) - [GCC 7.5.0], pyOpenSSL 20.0.1 (OpenSSL 1.1.1j  16 Feb 2021), cryptography 3.4.6, Platform Linux-4.19.112+-x86_64-with-Ubuntu-18.04-bionic\n",
            "2021-03-07 02:20:30 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor\n",
            "2021-03-07 02:20:30 [scrapy.crawler] INFO: Overridden settings:\n",
            "{'SPIDER_LOADER_WARN_ONLY': True}\n",
            "2021-03-07 02:20:30 [scrapy.extensions.telnet] INFO: Telnet Password: 2ae52b4aeff28c92\n",
            "2021-03-07 02:20:30 [scrapy.middleware] INFO: Enabled extensions:\n",
            "['scrapy.extensions.corestats.CoreStats',\n",
            " 'scrapy.extensions.telnet.TelnetConsole',\n",
            " 'scrapy.extensions.memusage.MemoryUsage',\n",
            " 'scrapy.extensions.logstats.LogStats']\n",
            "2021-03-07 02:20:30 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
            "['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
            " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
            " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
            " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
            " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
            " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
            " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
            " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
            " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
            " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
            " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
            "2021-03-07 02:20:30 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
            "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
            " 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',\n",
            " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
            " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
            " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
            "2021-03-07 02:20:30 [scrapy.middleware] INFO: Enabled item pipelines:\n",
            "[]\n",
            "2021-03-07 02:20:30 [scrapy.core.engine] INFO: Spider opened\n",
            "2021-03-07 02:20:30 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
            "2021-03-07 02:20:30 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023\n",
            "2021-03-07 02:20:31 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (308) to <GET http://quotes.toscrape.com/tag/humor/> from <GET http://quotes.toscrape.com/tag/humor>\n",
            "2021-03-07 02:20:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://quotes.toscrape.com/tag/humor/> (referer: None)\n",
            "2021-03-07 02:20:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://quotes.toscrape.com/tag/humor/> (referer: None)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/parsel/selector.py\", line 256, in xpath\n",
            "    **kwargs)\n",
            "  File \"src/lxml/etree.pyx\", line 1577, in lxml.etree._Element.xpath\n",
            "  File \"src/lxml/xpath.pxi\", line 307, in lxml.etree.XPathElementEvaluator.__call__\n",
            "  File \"src/lxml/xpath.pxi\", line 227, in lxml.etree._XPathEvaluatorBase._handle_result\n",
            "lxml.etree.XPathEvalError: Invalid expression\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scrapy/utils/defer.py\", line 120, in iter_errback\n",
            "    yield next(it)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scrapy/utils/python.py\", line 353, in __next__\n",
            "    return next(self.data)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scrapy/utils/python.py\", line 353, in __next__\n",
            "    return next(self.data)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scrapy/core/spidermw.py\", line 62, in _evaluate_iterable\n",
            "    for r in iterable:\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scrapy/spidermiddlewares/offsite.py\", line 29, in process_spider_output\n",
            "    for x in result:\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scrapy/core/spidermw.py\", line 62, in _evaluate_iterable\n",
            "    for r in iterable:\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scrapy/spidermiddlewares/referer.py\", line 340, in <genexpr>\n",
            "    return (_set_referer(r) for r in result or ())\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scrapy/core/spidermw.py\", line 62, in _evaluate_iterable\n",
            "    for r in iterable:\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scrapy/spidermiddlewares/urllength.py\", line 37, in <genexpr>\n",
            "    return (r for r in result or () if _filter(r))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scrapy/core/spidermw.py\", line 62, in _evaluate_iterable\n",
            "    for r in iterable:\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scrapy/spidermiddlewares/depth.py\", line 58, in <genexpr>\n",
            "    return (r for r in result or () if _filter(r))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scrapy/core/spidermw.py\", line 62, in _evaluate_iterable\n",
            "    for r in iterable:\n",
            "  File \"/content/toscrape_xpath.py\", line 30, in parse\n",
            "    next_page = response.xpath('//li.next a/attr(href)/text()').get()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scrapy/http/response/text.py\", line 139, in xpath\n",
            "    return self.selector.xpath(query, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/parsel/selector.py\", line 260, in xpath\n",
            "    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/six.py\", line 702, in reraise\n",
            "    raise value.with_traceback(tb)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/parsel/selector.py\", line 256, in xpath\n",
            "    **kwargs)\n",
            "  File \"src/lxml/etree.pyx\", line 1577, in lxml.etree._Element.xpath\n",
            "  File \"src/lxml/xpath.pxi\", line 307, in lxml.etree.XPathElementEvaluator.__call__\n",
            "  File \"src/lxml/xpath.pxi\", line 227, in lxml.etree._XPathEvaluatorBase._handle_result\n",
            "ValueError: XPath error: Invalid expression in //li.next a/attr(href)/text()\n",
            "2021-03-07 02:20:31 [scrapy.core.engine] INFO: Closing spider (finished)\n",
            "2021-03-07 02:20:31 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
            "{'downloader/request_bytes': 457,\n",
            " 'downloader/request_count': 2,\n",
            " 'downloader/request_method_count/GET': 2,\n",
            " 'downloader/response_bytes': 2670,\n",
            " 'downloader/response_count': 2,\n",
            " 'downloader/response_status_count/200': 1,\n",
            " 'downloader/response_status_count/308': 1,\n",
            " 'elapsed_time_seconds': 0.364443,\n",
            " 'finish_reason': 'finished',\n",
            " 'finish_time': datetime.datetime(2021, 3, 7, 2, 20, 31, 290085),\n",
            " 'log_count/DEBUG': 2,\n",
            " 'log_count/ERROR': 1,\n",
            " 'log_count/INFO': 10,\n",
            " 'memusage/max': 81588224,\n",
            " 'memusage/startup': 81588224,\n",
            " 'response_received_count': 1,\n",
            " 'scheduler/dequeued': 2,\n",
            " 'scheduler/dequeued/memory': 2,\n",
            " 'scheduler/enqueued': 2,\n",
            " 'scheduler/enqueued/memory': 2,\n",
            " 'spider_exceptions/ValueError': 1,\n",
            " 'start_time': datetime.datetime(2021, 3, 7, 2, 20, 30, 925642)}\n",
            "2021-03-07 02:20:31 [scrapy.core.engine] INFO: Spider closed (finished)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkKeG5VvMYgk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3778892c-25be-4d80-a09c-08b3f8a06c09"
      },
      "source": [
        "!scrapy runspider toscrape_xpath.py -o xpath_scraper_results.json -a tag=humor"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-03-07 02:20:37 [scrapy.utils.log] INFO: Scrapy 2.4.1 started (bot: scrapybot)\n",
            "2021-03-07 02:20:37 [scrapy.utils.log] INFO: Versions: lxml 4.2.6.0, libxml2 2.9.8, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 21.2.0, Python 3.7.10 (default, Feb 20 2021, 21:17:23) - [GCC 7.5.0], pyOpenSSL 20.0.1 (OpenSSL 1.1.1j  16 Feb 2021), cryptography 3.4.6, Platform Linux-4.19.112+-x86_64-with-Ubuntu-18.04-bionic\n",
            "2021-03-07 02:20:37 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor\n",
            "2021-03-07 02:20:37 [scrapy.crawler] INFO: Overridden settings:\n",
            "{'SPIDER_LOADER_WARN_ONLY': True}\n",
            "2021-03-07 02:20:37 [scrapy.extensions.telnet] INFO: Telnet Password: 6a18d911b8136310\n",
            "2021-03-07 02:20:37 [scrapy.middleware] INFO: Enabled extensions:\n",
            "['scrapy.extensions.corestats.CoreStats',\n",
            " 'scrapy.extensions.telnet.TelnetConsole',\n",
            " 'scrapy.extensions.memusage.MemoryUsage',\n",
            " 'scrapy.extensions.feedexport.FeedExporter',\n",
            " 'scrapy.extensions.logstats.LogStats']\n",
            "2021-03-07 02:20:37 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
            "['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
            " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
            " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
            " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
            " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
            " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
            " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
            " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
            " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
            " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
            " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
            "2021-03-07 02:20:37 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
            "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
            " 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',\n",
            " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
            " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
            " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
            "2021-03-07 02:20:37 [scrapy.middleware] INFO: Enabled item pipelines:\n",
            "[]\n",
            "2021-03-07 02:20:37 [scrapy.core.engine] INFO: Spider opened\n",
            "2021-03-07 02:20:37 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
            "2021-03-07 02:20:37 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023\n",
            "2021-03-07 02:20:37 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (308) to <GET http://quotes.toscrape.com/tag/humor/> from <GET http://quotes.toscrape.com/tag/humor>\n",
            "2021-03-07 02:20:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://quotes.toscrape.com/tag/humor/> (referer: None)\n",
            "2021-03-07 02:20:37 [scrapy.core.scraper] ERROR: Spider error processing <GET http://quotes.toscrape.com/tag/humor/> (referer: None)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/parsel/selector.py\", line 256, in xpath\n",
            "    **kwargs)\n",
            "  File \"src/lxml/etree.pyx\", line 1577, in lxml.etree._Element.xpath\n",
            "  File \"src/lxml/xpath.pxi\", line 307, in lxml.etree.XPathElementEvaluator.__call__\n",
            "  File \"src/lxml/xpath.pxi\", line 227, in lxml.etree._XPathEvaluatorBase._handle_result\n",
            "lxml.etree.XPathEvalError: Invalid expression\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scrapy/utils/defer.py\", line 120, in iter_errback\n",
            "    yield next(it)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scrapy/utils/python.py\", line 353, in __next__\n",
            "    return next(self.data)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scrapy/utils/python.py\", line 353, in __next__\n",
            "    return next(self.data)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scrapy/core/spidermw.py\", line 62, in _evaluate_iterable\n",
            "    for r in iterable:\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scrapy/spidermiddlewares/offsite.py\", line 29, in process_spider_output\n",
            "    for x in result:\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scrapy/core/spidermw.py\", line 62, in _evaluate_iterable\n",
            "    for r in iterable:\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scrapy/spidermiddlewares/referer.py\", line 340, in <genexpr>\n",
            "    return (_set_referer(r) for r in result or ())\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scrapy/core/spidermw.py\", line 62, in _evaluate_iterable\n",
            "    for r in iterable:\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scrapy/spidermiddlewares/urllength.py\", line 37, in <genexpr>\n",
            "    return (r for r in result or () if _filter(r))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scrapy/core/spidermw.py\", line 62, in _evaluate_iterable\n",
            "    for r in iterable:\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scrapy/spidermiddlewares/depth.py\", line 58, in <genexpr>\n",
            "    return (r for r in result or () if _filter(r))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scrapy/core/spidermw.py\", line 62, in _evaluate_iterable\n",
            "    for r in iterable:\n",
            "  File \"/content/toscrape_xpath.py\", line 30, in parse\n",
            "    next_page = response.xpath('//li.next a/attr(href)/text()').get()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/scrapy/http/response/text.py\", line 139, in xpath\n",
            "    return self.selector.xpath(query, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/parsel/selector.py\", line 260, in xpath\n",
            "    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/six.py\", line 702, in reraise\n",
            "    raise value.with_traceback(tb)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/parsel/selector.py\", line 256, in xpath\n",
            "    **kwargs)\n",
            "  File \"src/lxml/etree.pyx\", line 1577, in lxml.etree._Element.xpath\n",
            "  File \"src/lxml/xpath.pxi\", line 307, in lxml.etree.XPathElementEvaluator.__call__\n",
            "  File \"src/lxml/xpath.pxi\", line 227, in lxml.etree._XPathEvaluatorBase._handle_result\n",
            "ValueError: XPath error: Invalid expression in //li.next a/attr(href)/text()\n",
            "2021-03-07 02:20:37 [scrapy.core.engine] INFO: Closing spider (finished)\n",
            "2021-03-07 02:20:37 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
            "{'downloader/request_bytes': 457,\n",
            " 'downloader/request_count': 2,\n",
            " 'downloader/request_method_count/GET': 2,\n",
            " 'downloader/response_bytes': 2670,\n",
            " 'downloader/response_count': 2,\n",
            " 'downloader/response_status_count/200': 1,\n",
            " 'downloader/response_status_count/308': 1,\n",
            " 'elapsed_time_seconds': 0.358673,\n",
            " 'finish_reason': 'finished',\n",
            " 'finish_time': datetime.datetime(2021, 3, 7, 2, 20, 37, 931488),\n",
            " 'log_count/DEBUG': 2,\n",
            " 'log_count/ERROR': 1,\n",
            " 'log_count/INFO': 10,\n",
            " 'memusage/max': 81592320,\n",
            " 'memusage/startup': 81592320,\n",
            " 'response_received_count': 1,\n",
            " 'scheduler/dequeued': 2,\n",
            " 'scheduler/dequeued/memory': 2,\n",
            " 'scheduler/enqueued': 2,\n",
            " 'scheduler/enqueued/memory': 2,\n",
            " 'spider_exceptions/ValueError': 1,\n",
            " 'start_time': datetime.datetime(2021, 3, 7, 2, 20, 37, 572815)}\n",
            "2021-03-07 02:20:37 [scrapy.core.engine] INFO: Spider closed (finished)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}